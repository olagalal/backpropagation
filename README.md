# Backpropagation

[![Shields.io](https://img.shields.io/badge/type-college%20project-orange?style=flat)](http://shields.io/)

Backpropagation algorithms are a family of methods used to efficiently train artificial neural networks following a gradient-based optimization  algorithm that exploits the chain rule. Here I used sigmoid function as activation function, and the training example is the logical AND gate. 

```
trainExamples = [
        [[0,0], [0]],
        [[0,1], [0]],
        [[1,0], [0]],
        [[1,1], [1]]
	]
```	
	
This project was made for **(Machine Learning - Forth Year)** in my college.

## License
This project is available under the terms of [MIT License](https://choosealicense.com/licenses/mit/)